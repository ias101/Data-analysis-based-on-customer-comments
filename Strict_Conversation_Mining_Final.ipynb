{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81dad607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b572b53",
   "metadata": {},
   "source": [
    "Change file name according to what it is saved as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5673af18",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Group12-Final_code/result.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4280/2555974372.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Group12-Final_code/result.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Group12-Final_code/result.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = pd.read_csv('Group12-Final_code/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d084dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[['user_id_str', 'in_reply_to_status_id_str', 'in_reply_to_user_id_str', 'id_str', 'entity_user_mentions']] = result[['user_id_str', 'in_reply_to_status_id_str', 'in_reply_to_user_id_str', 'id_str', 'entity_user_mentions']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "73c97423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>entity_user_mentions</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-22 12:20:00</td>\n",
       "      <td>1.1311728589510246e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>393374091</td>\n",
       "      <td>nan</td>\n",
       "      <td>La ruta de easyJet entre Londres y Menorca tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-22 12:20:01</td>\n",
       "      <td>1.1311728641478084e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3420691215</td>\n",
       "      <td>('bttr_as1', '880417607865815040'),('goody_tra...</td>\n",
       "      <td>RT @bttr_as1: @goody_tracy Here’s a list of so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-05-22 12:20:02</td>\n",
       "      <td>1.1311728679854858e+18</td>\n",
       "      <td>394376606.0</td>\n",
       "      <td>1.1310329162328268e+18</td>\n",
       "      <td>394376606</td>\n",
       "      <td>('British_Airways', '18332190')</td>\n",
       "      <td>@British_Airways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-22 12:20:12</td>\n",
       "      <td>1.1311729094630276e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>36488556</td>\n",
       "      <td>('TheRaceRadio', '227687574'),('AmericanAir', ...</td>\n",
       "      <td>RT @TheRaceRadio: Nice change by @AmericanAir....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-05-22 12:20:28</td>\n",
       "      <td>1.131172975682605e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>14193348</td>\n",
       "      <td>('sandeeprrao1991', '2835499934'),('BLRAirport...</td>\n",
       "      <td>RT @sandeeprrao1991: BREAKING:- KLM to fly 3x ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     tweet_created_at                  id_str  \\\n",
       "0           0  2019-05-22 12:20:00  1.1311728589510246e+18   \n",
       "1           1  2019-05-22 12:20:01  1.1311728641478084e+18   \n",
       "2           2  2019-05-22 12:20:02  1.1311728679854858e+18   \n",
       "3           3  2019-05-22 12:20:12  1.1311729094630276e+18   \n",
       "4           4  2019-05-22 12:20:28   1.131172975682605e+18   \n",
       "\n",
       "  in_reply_to_user_id_str in_reply_to_status_id_str user_id_str  \\\n",
       "0                     nan                       nan   393374091   \n",
       "1                     nan                       nan  3420691215   \n",
       "2             394376606.0    1.1310329162328268e+18   394376606   \n",
       "3                     nan                       nan    36488556   \n",
       "4                     nan                       nan    14193348   \n",
       "\n",
       "                                entity_user_mentions  \\\n",
       "0                                                nan   \n",
       "1  ('bttr_as1', '880417607865815040'),('goody_tra...   \n",
       "2                    ('British_Airways', '18332190')   \n",
       "3  ('TheRaceRadio', '227687574'),('AmericanAir', ...   \n",
       "4  ('sandeeprrao1991', '2835499934'),('BLRAirport...   \n",
       "\n",
       "                                           full_text  \n",
       "0  La ruta de easyJet entre Londres y Menorca tra...  \n",
       "1  RT @bttr_as1: @goody_tracy Here’s a list of so...  \n",
       "2                                   @British_Airways  \n",
       "3  RT @TheRaceRadio: Nice change by @AmericanAir....  \n",
       "4  RT @sandeeprrao1991: BREAKING:- KLM to fly 3x ...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c921e13",
   "metadata": {},
   "source": [
    "Only take valid data rows. These are rows where 'in_reply_to_user_id_str' and 'in_reply_to_status_id_str' either both have nan or an id string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b81f13a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3702539\n",
      "1690413\n",
      "5392952\n",
      "5805153\n",
      "412201\n"
     ]
    }
   ],
   "source": [
    "df_start = result[(result['in_reply_to_user_id_str']=='nan')&(result['in_reply_to_status_id_str']=='nan')]\n",
    "df_valid = result[(result['in_reply_to_user_id_str']!='nan')&(result['in_reply_to_status_id_str']!='nan')]\n",
    "\n",
    "#concats df_valid to the end up df_start\n",
    "df_all = pd.concat([df_start, df_valid])\n",
    "\n",
    "#print lengths to see how much data we lost -> len(result) - len(df_all)\n",
    "print(len(df_start))\n",
    "print(len(df_valid))\n",
    "print(len(df_all))\n",
    "print(len(result))\n",
    "print(len(result) - len(df_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715a673",
   "metadata": {},
   "source": [
    "Extract user mention id (id's instead of screen names) from 'entity_user_mentions' and create a list of them in a new column 'entity_user_mention_id'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ae41abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/1367534190.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_start['entity_user_mention_id'] = [re.findall(r\"\\d+\",n) for n in df_start['entity_user_mentions']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               entity_user_mention_id\n",
      "0                                                  []\n",
      "1   [1, 880417607865815040, 1000793307688058880, 2...\n",
      "3                     [227687574, 22536055, 13192972]\n",
      "4             [1991, 2835499934, 3274266002, 8279892]\n",
      "5                                                  []\n",
      "6                                          [18332190]\n",
      "8                               [22536055, 234423098]\n",
      "13                                       [2383996850]\n",
      "16                                         [22536055]\n",
      "18         [45732580, 21867685, 31122496, 1327721360]\n",
      "20                                                 []\n",
      "24                                          [5920532]\n",
      "25                            [381426637, 1542862735]\n",
      "26                                         [22536055]\n",
      "27             [2, 421475959, 1542862735, 2689427773]\n",
      "29                   [86483747, 408877491, 471878399]\n",
      "31  [1000793307688058880, 799402837675380736, 2789...\n",
      "32                              [38676903, 131494378]\n",
      "34                                                 []\n",
      "35                              [264248576, 18332190]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "df_start['entity_user_mention_id'] = [re.findall(r\"\\d+\",n) for n in df_start['entity_user_mentions']]\n",
    "print(df_start[['entity_user_mention_id']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b3305",
   "metadata": {},
   "source": [
    "Create df_all_sel, a df with all the rows/Tweets where the airlines are mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34032091",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_list = ['56377143','106062176','18332190','22536055','124476322','26223583','2182373406','38676903','1542862735',\\\n",
    "                '253340062','218730857','45621423','20626359']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ad45f0b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/758079258.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_start['entity_user_mention_id'] = df_start['entity_user_mention_id'].apply(lambda x:list(set(x).intersection(set(airline_list))))\n",
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/758079258.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_start['entity_user_mention_id_count'] = df_start['entity_user_mention_id'].str.len()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165222\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "df_start['entity_user_mention_id'] = df_start['entity_user_mention_id'].apply(lambda x:list(set(x).intersection(set(airline_list))))\n",
    "df_start['entity_user_mention_id_count'] = df_start['entity_user_mention_id'].str.len()\n",
    "\n",
    "#all start tweets where there are user mentions\n",
    "df_start_sel = df_start[df_start['entity_user_mention_id_count']!= 0]\n",
    "print(len(df_start_sel))# all start Tweets where an airline was mentioned\n",
    "print(df_start_sel['entity_user_mention_id_count'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5844cce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/2974980083.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_start_sel['user_id_insection'] = df_start_sel['user_id_str'].apply(lambda x:list(set(x).intersection(set(airline_list))))\n",
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/2974980083.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_start_sel['user_id_insection_count'] = df_start_sel['user_id_insection'].str.len()\n"
     ]
    }
   ],
   "source": [
    "df_start_sel['user_id_insection'] = df_start_sel['user_id_str'].apply(lambda x:list(set(x).intersection(set(airline_list))))\n",
    "df_start_sel['user_id_insection_count'] = df_start_sel['user_id_insection'].str.len()\n",
    "\n",
    "df_start_del = df_start_sel[df_start_sel['user_id_insection_count'] == 0]\n",
    "# print(len(df_start_del))\n",
    "# print(len(df_start_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3390a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start_del['entity_user_mention_id_count'] = df_start_del['entity_user_mention_id_count'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa8624bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reply1 = df_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "72faa9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(cell):\n",
    "    cell = ''.join(c for c in cell if c not in \"'[]\")\n",
    "    cell = cell.split(', ')\n",
    "    return cell\n",
    "df_con = df_start_del.copy()\n",
    "df_con['conversation'] = df_con['full_text'].apply(str_to_list)\n",
    "df_con['con_id_str_list'] = df_con['id_str'].apply(str_to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d38d3d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>entity_user_mentions</th>\n",
       "      <th>full_text</th>\n",
       "      <th>entity_user_mention_id</th>\n",
       "      <th>entity_user_mention_id_count</th>\n",
       "      <th>user_id_insection</th>\n",
       "      <th>user_id_insection_count</th>\n",
       "      <th>conversation</th>\n",
       "      <th>con_id_str_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-05-22 12:20:12</td>\n",
       "      <td>1.1311729094630276e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>36488556</td>\n",
       "      <td>('TheRaceRadio', '227687574'),('AmericanAir', ...</td>\n",
       "      <td>RT @TheRaceRadio: Nice change by @AmericanAir....</td>\n",
       "      <td>[22536055]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[RT @TheRaceRadio: Nice change by @AmericanAir...</td>\n",
       "      <td>[1.1311729094630276e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-05-22 12:20:36</td>\n",
       "      <td>1.1311730105080628e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1662186764</td>\n",
       "      <td>('British_Airways', '18332190')</td>\n",
       "      <td>Thanks @British_Airways I really needed the ex...</td>\n",
       "      <td>[18332190]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Thanks @British_Airways I really needed the e...</td>\n",
       "      <td>[1.1311730105080628e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2019-05-22 12:20:49</td>\n",
       "      <td>1.1311730651220788e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2730172562</td>\n",
       "      <td>('AmericanAir', '22536055'),('EWRairport', '23...</td>\n",
       "      <td>So @AmericanAir @EWRairport lied to an old lad...</td>\n",
       "      <td>[22536055]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[So @AmericanAir @EWRairport lied to an old la...</td>\n",
       "      <td>[1.1311730651220788e+18]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     tweet_created_at                  id_str  \\\n",
       "3           3  2019-05-22 12:20:12  1.1311729094630276e+18   \n",
       "6           6  2019-05-22 12:20:36  1.1311730105080628e+18   \n",
       "8           8  2019-05-22 12:20:49  1.1311730651220788e+18   \n",
       "\n",
       "  in_reply_to_user_id_str in_reply_to_status_id_str user_id_str  \\\n",
       "3                     nan                       nan    36488556   \n",
       "6                     nan                       nan  1662186764   \n",
       "8                     nan                       nan  2730172562   \n",
       "\n",
       "                                entity_user_mentions  \\\n",
       "3  ('TheRaceRadio', '227687574'),('AmericanAir', ...   \n",
       "6                    ('British_Airways', '18332190')   \n",
       "8  ('AmericanAir', '22536055'),('EWRairport', '23...   \n",
       "\n",
       "                                           full_text entity_user_mention_id  \\\n",
       "3  RT @TheRaceRadio: Nice change by @AmericanAir....             [22536055]   \n",
       "6  Thanks @British_Airways I really needed the ex...             [18332190]   \n",
       "8  So @AmericanAir @EWRairport lied to an old lad...             [22536055]   \n",
       "\n",
       "   entity_user_mention_id_count user_id_insection  user_id_insection_count  \\\n",
       "3                             1                []                        0   \n",
       "6                             1                []                        0   \n",
       "8                             1                []                        0   \n",
       "\n",
       "                                        conversation           con_id_str_list  \n",
       "3  [RT @TheRaceRadio: Nice change by @AmericanAir...  [1.1311729094630276e+18]  \n",
       "6  [Thanks @British_Airways I really needed the e...  [1.1311730105080628e+18]  \n",
       "8  [So @AmericanAir @EWRairport lied to an old la...  [1.1311730651220788e+18]  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_con.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a4387",
   "metadata": {},
   "source": [
    "CHANGE AIRLINE CODE according to which airline you want conversations for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d38c2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conversation(airline_code: str):\n",
    "    df_con['judgement'] = df_con['entity_user_mention_id'].apply(lambda x: airline_code in x)\n",
    "    air_56377143 = df_con[df_con['judgement']==True]\n",
    "    print(len(df_con))\n",
    "    df_reply_id_list = df_reply1['in_reply_to_status_id_str'].tolist()\n",
    "    df_reply_id_sl = list(set(df_reply_id_list))\n",
    "    air_56377143['judgment_reply'] = air_56377143[['id_str']].isin(df_reply_id_sl)\n",
    "    air_56377143.head()\n",
    "    air_56377143_use = air_56377143[air_56377143['judgment_reply']==True]\n",
    "    mask = air_56377143_use['id_str'].tolist()\n",
    "    print(len(air_56377143_use))\n",
    "    df_reply_56377143 = df_reply1[df_reply1['in_reply_to_status_id_str'].isin(mask)]\n",
    "    df_reply_56377143['intersection_judgement1'] = df_reply_56377143['user_id_str'].apply(lambda x:list(set(x).intersection(set(air_56377143_use['user_id_str'].tolist()))))\n",
    "    df_reply_56377143['judgement1'] = np.where(df_reply_56377143['intersection_judgement1']==1,True,False)\n",
    "\n",
    "    df_reply_56377143['judgement2'] = df_reply_56377143['user_id_str'].apply(lambda x:x == airline_code)\n",
    "    df_reply_56377143_use = df_reply_56377143[(df_reply_56377143['judgement1'] == True)|(df_reply_56377143['judgement2'] == True)]\n",
    "    air_56377143_test = air_56377143_use[['tweet_created_at','id_str','in_reply_to_user_id_str',\\\n",
    "                                                  'in_reply_to_status_id_str','user_id_str','entity_user_mentions',\\\n",
    "                                                  'entity_user_mention_id','full_text','conversation','con_id_str_list']].copy()\n",
    "    reply_56377143_v1 = df_reply_56377143_use[['tweet_created_at','id_str','in_reply_to_user_id_str',\\\n",
    "                                                  'in_reply_to_status_id_str','user_id_str','full_text']].copy()\n",
    "    air_56377143_test['con_id_str_list1'] = air_56377143_test['con_id_str_list'].apply(lambda x:list())\n",
    "    reply_56377143_v1['in_reply_to_status_id_str'] = reply_56377143_v1['in_reply_to_status_id_str'].astype(str)\n",
    "    air_56377143_test['id_str'] = air_56377143_test['id_str'].astype(str)\n",
    "\n",
    "    for index,info in reply_56377143_v1.iterrows():\n",
    "        index = air_56377143_test.index[air_56377143_test.id_str == info['in_reply_to_status_id_str']].tolist()[0]\n",
    "        if info['id_str'] not in air_56377143_test['con_id_str_list1'][index]:\n",
    "            air_56377143_test['con_id_str_list1'][index].append(info['id_str'])\n",
    "            air_56377143_test['conversation'][index].append(info['full_text'])\n",
    "    reply_1 = []\n",
    "    for index,info in air_56377143_test[['con_id_str_list1']].iterrows():\n",
    "        reply_1 = reply_1 + info[0]\n",
    "    df_reply_1 = df_reply1.copy()\n",
    "    df_reply_1 = df_reply_1\n",
    "    df_reply_1 = df_reply_1[df_reply_1['id_str'].isin(reply_1)]\n",
    "    air_56377143_test['con_id_str_list2'] = air_56377143_test['con_id_str_list'].apply(lambda x:list())\n",
    "    air_56377143_test['con_id_str_list2']\n",
    "    df_reply_id_2 = df_reply1['in_reply_to_status_id_str'].tolist()\n",
    "    df_reply_id_sl = list(set(df_reply_id_list))\n",
    "    df_reply_1['judgment_reply'] = df_reply_1[['id_str']].isin(df_reply_id_sl)\n",
    "    df_reply_1.head()\n",
    "    df_reply_1_use = df_reply_1[df_reply_1['judgment_reply']==True]\n",
    "    mask = df_reply_1_use['id_str'].tolist()\n",
    "    df_reply_56377143_2 = df_reply1[df_reply1['in_reply_to_status_id_str'].isin(mask)]\n",
    "    final_list = df_reply_1_use['user_id_str'].tolist() + air_56377143_test['user_id_str'].tolist()\n",
    "    df_reply_56377143_2['intersection_judgement1'] = df_reply_56377143_2['user_id_str'].apply(lambda x:list(set(x).intersection(set(final_list))))\n",
    "    df_reply_56377143_2['judgement1'] = np.where(df_reply_56377143_2['intersection_judgement1']==1,True,False)\n",
    "\n",
    "    df_reply_56377143_2['judgement2'] = df_reply_56377143_2['user_id_str'].apply(lambda x:x == airline_code)\n",
    "    df_reply_56377143_2_use = df_reply_56377143_2[(df_reply_56377143_2['judgement1'] == True)|(df_reply_56377143_2['judgement2'] == True)]\n",
    "    for index,info in df_reply_56377143_2_use.iterrows():\n",
    "        for i,info2 in air_56377143_test.iterrows():\n",
    "            if info['in_reply_to_status_id_str'] in info2['con_id_str_list1']: \n",
    "                index = air_56377143_test.index[air_56377143_test.id_str == info2['id_str']].tolist()[0]\n",
    "                if info['id_str'] not in air_56377143_test['con_id_str_list2'][index]:\n",
    "                    air_56377143_test['con_id_str_list2'][index].append(info['id_str'])\n",
    "                    air_56377143_test['conversation'][index].append(info['full_text'])\n",
    "    reply_2 = []\n",
    "    for index,info in air_56377143_test[['con_id_str_list2']].iterrows():\n",
    "        reply_2 = reply_2 + info[0]\n",
    "    df_reply_2 = df_reply1.copy()\n",
    "    df_reply_2 = df_reply_2[df_reply_2['id_str'].isin(reply_2)]\n",
    "    air_56377143_test['con_id_str_list3'] = air_56377143_test['con_id_str_list'].apply(lambda x:list())\n",
    "    air_56377143_test['con_id_str_list3']\n",
    "    df_reply_id_3 = df_reply1['in_reply_to_status_id_str'].tolist()\n",
    "    df_reply_id_sl = list(set(df_reply_id_list))\n",
    "    df_reply_2['judgment_reply'] = df_reply_2[['id_str']].isin(df_reply_id_sl)\n",
    "    df_reply_2.head()\n",
    "    df_reply_2_use = df_reply_2[df_reply_2['judgment_reply']==True]\n",
    "    mask = df_reply_2_use['id_str'].tolist()\n",
    "    df_reply_56377143_3 = df_reply1[df_reply1['in_reply_to_status_id_str'].isin(mask)]\n",
    "    final_list = df_reply_1_use['user_id_str'].tolist() + air_56377143_test['user_id_str'].tolist() + df_reply_2_use['user_id_str'].tolist()\n",
    "    df_reply_56377143_3['intersection_judgement1'] = df_reply_56377143_3['user_id_str'].apply(lambda x:list(set(x).intersection(set(final_list))))\n",
    "    df_reply_56377143_3['judgement1'] = np.where(df_reply_56377143_3['intersection_judgement1']==1,True,False)\n",
    "    df_reply_56377143_3['judgement2'] = df_reply_56377143_3['user_id_str'].apply(lambda x:x == airline_code)\n",
    "    df_reply_56377143_3_use = df_reply_56377143_3[(df_reply_56377143_3['judgement1'] == True)|(df_reply_56377143_3['judgement2'] == True)]\n",
    "    air_56377143_test['full_conversation_ids'] = air_56377143_test['con_id_str_list'] + air_56377143_test['con_id_str_list1'] + air_56377143_test['con_id_str_list2']\n",
    "    air_56377143_test.to_csv(f'conversations_{airline_code}', index=False)\n",
    "    return air_56377143_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ff62a8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/2460289222.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  air_56377143['judgment_reply'] = air_56377143[['id_str']].isin(df_reply_id_sl)\n",
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/2460289222.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reply_56377143['intersection_judgement1'] = df_reply_56377143['user_id_str'].apply(lambda x:list(set(x).intersection(set(air_56377143_use['user_id_str'].tolist()))))\n",
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/2460289222.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reply_56377143['judgement1'] = np.where(df_reply_56377143['intersection_judgement1']==1,True,False)\n",
      "C:\\Users\\hetvi\\AppData\\Local\\Temp/ipykernel_18836/2460289222.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reply_56377143['judgement2'] = df_reply_56377143['user_id_str'].apply(lambda x:x == airline_code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>entity_user_mentions</th>\n",
       "      <th>entity_user_mention_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>conversation</th>\n",
       "      <th>con_id_str_list</th>\n",
       "      <th>con_id_str_list1</th>\n",
       "      <th>con_id_str_list2</th>\n",
       "      <th>con_id_str_list3</th>\n",
       "      <th>full_conversation_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10845</th>\n",
       "      <td>2019-05-23 07:21:41</td>\n",
       "      <td>1.131460172835152e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>38915602</td>\n",
       "      <td>('airberlin', '26223583'),('eurowings', '26462...</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Gute Nachrichten!! @airberlin fliegt wieder, @...</td>\n",
       "      <td>[Gute Nachrichten!! @airberlin fliegt wieder, ...</td>\n",
       "      <td>[1.131460172835152e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.131460172835152e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500375</th>\n",
       "      <td>2019-06-18 08:56:00</td>\n",
       "      <td>1.1409059916403548e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>17688643</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Heute back to the future mit @airberlin!</td>\n",
       "      <td>[Heute back to the future mit @airberlin! ]</td>\n",
       "      <td>[1.1409059916403548e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.1409059916403548e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682085</th>\n",
       "      <td>2019-06-26 12:58:37</td>\n",
       "      <td>1.14386615313306e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>402012252</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>People of twitter, I've just received a refund...</td>\n",
       "      <td>[People of twitter, Ive just received a refund...</td>\n",
       "      <td>[1.14386615313306e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.14386615313306e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840200</th>\n",
       "      <td>2019-07-04 06:11:57</td>\n",
       "      <td>1.1466629144111064e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>312134808</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Now at #TXL still flying @airberlin #ber4evr</td>\n",
       "      <td>[Now at #TXL still flying @airberlin #ber4evr ]</td>\n",
       "      <td>[1.1466629144111064e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.1466629144111064e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841780</th>\n",
       "      <td>2019-07-04 08:39:07</td>\n",
       "      <td>1.1466999493059953e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>17482096</td>\n",
       "      <td>('biobooster', '116841893'),('airberlin', '262...</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Post inspired by @biobooster. Perhaps the last...</td>\n",
       "      <td>[Post inspired by @biobooster. Perhaps the las...</td>\n",
       "      <td>[1.1466999493059953e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.1466999493059953e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905945</th>\n",
       "      <td>2019-08-30 14:25:09</td>\n",
       "      <td>1.167443139063419e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1128733448045322241</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>yo @airberlin one ticket please</td>\n",
       "      <td>[yo @airberlin one ticket please]</td>\n",
       "      <td>[1.167443139063419e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.167443139063419e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313301</th>\n",
       "      <td>2019-09-24 19:49:11</td>\n",
       "      <td>1.1765843832953815e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>15055852</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Hat bei @airberlin ja auch schon so gut geklap...</td>\n",
       "      <td>[Hat bei @airberlin ja auch schon so gut gekla...</td>\n",
       "      <td>[1.1765843832953815e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.1765843832953815e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482047</th>\n",
       "      <td>2019-10-28 22:42:42</td>\n",
       "      <td>1.188949239147225e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>4311425481</td>\n",
       "      <td>('airberlin', '26223583'),('MUC_Airport', '605...</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Moments which are gone since two years but sti...</td>\n",
       "      <td>[Moments which are gone since two years but st...</td>\n",
       "      <td>[1.188949239147225e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.188949239147225e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515956</th>\n",
       "      <td>2019-10-31 21:33:55</td>\n",
       "      <td>1.1900190893113836e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>14612265</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Oh @airberlin, only 4 years ago. Feels like ye...</td>\n",
       "      <td>[Oh @airberlin, only 4 years ago. Feels like y...</td>\n",
       "      <td>[1.1900190893113836e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.1900190893113836e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712310</th>\n",
       "      <td>2019-11-14 01:05:32</td>\n",
       "      <td>1.1947833891083756e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>37687736</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Danke für den Medienpreis Luft- und Raumfahrt ...</td>\n",
       "      <td>[Danke für den Medienpreis Luft- und Raumfahrt...</td>\n",
       "      <td>[1.1947833891083756e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.1947833891083756e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903675</th>\n",
       "      <td>2019-11-23 23:05:07</td>\n",
       "      <td>1.1983769635739853e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>15955335</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Die @airberlin Schoki performt immer noch. Ich...</td>\n",
       "      <td>[Die @airberlin Schoki performt immer noch. Ic...</td>\n",
       "      <td>[1.1983769635739853e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.1983769635739853e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024084</th>\n",
       "      <td>2019-12-03 19:23:19</td>\n",
       "      <td>1.2019450233628713e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>541085722</td>\n",
       "      <td>('airberlin', '26223583'),('AirCanada', '54904...</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>I thought @airberlin’s customer service sucked...</td>\n",
       "      <td>[I thought @airberlin’s customer service sucke...</td>\n",
       "      <td>[1.2019450233628713e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.2019450233628713e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920865</th>\n",
       "      <td>2020-02-07 21:58:18</td>\n",
       "      <td>1.2259016251282268e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>14612265</td>\n",
       "      <td>('airberlin', '26223583'),('Sansibar_Sylt', '3...</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>WTF? 😱 Hmmm... Da ist schon nen Unterschied. 😂...</td>\n",
       "      <td>[WTF? 😱 Hmmm... Da ist schon nen Unterschied. ...</td>\n",
       "      <td>[1.2259016251282268e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.2259016251282268e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247333</th>\n",
       "      <td>2020-02-22 10:45:58</td>\n",
       "      <td>1.2311682480471204e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2817406821</td>\n",
       "      <td>('Airbus', '15425377'),('airberlin', '26223583...</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Was this steam-powered @Airbus #A319 the downf...</td>\n",
       "      <td>[Was this steam-powered @Airbus #A319 the down...</td>\n",
       "      <td>[1.2311682480471204e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.2311682480471204e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631002</th>\n",
       "      <td>2020-01-16 19:24:03</td>\n",
       "      <td>1.2178902749842432e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>14612265</td>\n",
       "      <td>('airberlin', '26223583')</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Interesting liveries! Somehow @airberlin is st...</td>\n",
       "      <td>[Interesting liveries! Somehow @airberlin is s...</td>\n",
       "      <td>[1.2178902749842432e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.2178902749842432e+18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682425</th>\n",
       "      <td>2020-02-21 21:09:24</td>\n",
       "      <td>1.2309627492676403e+18</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>211532417</td>\n",
       "      <td>('manairport', '19913832'),('Gatwick_Airport',...</td>\n",
       "      <td>[26223583]</td>\n",
       "      <td>Positioning into @manairport from @Gatwick_Air...</td>\n",
       "      <td>[Positioning into @manairport from @Gatwick_Ai...</td>\n",
       "      <td>[1.2309627492676403e+18]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.2309627492676403e+18]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet_created_at                  id_str in_reply_to_user_id_str  \\\n",
       "10845    2019-05-23 07:21:41   1.131460172835152e+18                     nan   \n",
       "500375   2019-06-18 08:56:00  1.1409059916403548e+18                     nan   \n",
       "682085   2019-06-26 12:58:37    1.14386615313306e+18                     nan   \n",
       "840200   2019-07-04 06:11:57  1.1466629144111064e+18                     nan   \n",
       "841780   2019-07-04 08:39:07  1.1466999493059953e+18                     nan   \n",
       "1905945  2019-08-30 14:25:09   1.167443139063419e+18                     nan   \n",
       "2313301  2019-09-24 19:49:11  1.1765843832953815e+18                     nan   \n",
       "2482047  2019-10-28 22:42:42   1.188949239147225e+18                     nan   \n",
       "2515956  2019-10-31 21:33:55  1.1900190893113836e+18                     nan   \n",
       "2712310  2019-11-14 01:05:32  1.1947833891083756e+18                     nan   \n",
       "2903675  2019-11-23 23:05:07  1.1983769635739853e+18                     nan   \n",
       "3024084  2019-12-03 19:23:19  1.2019450233628713e+18                     nan   \n",
       "3920865  2020-02-07 21:58:18  1.2259016251282268e+18                     nan   \n",
       "4247333  2020-02-22 10:45:58  1.2311682480471204e+18                     nan   \n",
       "5631002  2020-01-16 19:24:03  1.2178902749842432e+18                     nan   \n",
       "5682425  2020-02-21 21:09:24  1.2309627492676403e+18                     nan   \n",
       "\n",
       "        in_reply_to_status_id_str          user_id_str  \\\n",
       "10845                         nan             38915602   \n",
       "500375                        nan             17688643   \n",
       "682085                        nan            402012252   \n",
       "840200                        nan            312134808   \n",
       "841780                        nan             17482096   \n",
       "1905945                       nan  1128733448045322241   \n",
       "2313301                       nan             15055852   \n",
       "2482047                       nan           4311425481   \n",
       "2515956                       nan             14612265   \n",
       "2712310                       nan             37687736   \n",
       "2903675                       nan             15955335   \n",
       "3024084                       nan            541085722   \n",
       "3920865                       nan             14612265   \n",
       "4247333                       nan           2817406821   \n",
       "5631002                       nan             14612265   \n",
       "5682425                       nan            211532417   \n",
       "\n",
       "                                      entity_user_mentions  \\\n",
       "10845    ('airberlin', '26223583'),('eurowings', '26462...   \n",
       "500375                           ('airberlin', '26223583')   \n",
       "682085                           ('airberlin', '26223583')   \n",
       "840200                           ('airberlin', '26223583')   \n",
       "841780   ('biobooster', '116841893'),('airberlin', '262...   \n",
       "1905945                          ('airberlin', '26223583')   \n",
       "2313301                          ('airberlin', '26223583')   \n",
       "2482047  ('airberlin', '26223583'),('MUC_Airport', '605...   \n",
       "2515956                          ('airberlin', '26223583')   \n",
       "2712310                          ('airberlin', '26223583')   \n",
       "2903675                          ('airberlin', '26223583')   \n",
       "3024084  ('airberlin', '26223583'),('AirCanada', '54904...   \n",
       "3920865  ('airberlin', '26223583'),('Sansibar_Sylt', '3...   \n",
       "4247333  ('Airbus', '15425377'),('airberlin', '26223583...   \n",
       "5631002                          ('airberlin', '26223583')   \n",
       "5682425  ('manairport', '19913832'),('Gatwick_Airport',...   \n",
       "\n",
       "        entity_user_mention_id  \\\n",
       "10845               [26223583]   \n",
       "500375              [26223583]   \n",
       "682085              [26223583]   \n",
       "840200              [26223583]   \n",
       "841780              [26223583]   \n",
       "1905945             [26223583]   \n",
       "2313301             [26223583]   \n",
       "2482047             [26223583]   \n",
       "2515956             [26223583]   \n",
       "2712310             [26223583]   \n",
       "2903675             [26223583]   \n",
       "3024084             [26223583]   \n",
       "3920865             [26223583]   \n",
       "4247333             [26223583]   \n",
       "5631002             [26223583]   \n",
       "5682425             [26223583]   \n",
       "\n",
       "                                                 full_text  \\\n",
       "10845    Gute Nachrichten!! @airberlin fliegt wieder, @...   \n",
       "500375           Heute back to the future mit @airberlin!    \n",
       "682085   People of twitter, I've just received a refund...   \n",
       "840200       Now at #TXL still flying @airberlin #ber4evr    \n",
       "841780   Post inspired by @biobooster. Perhaps the last...   \n",
       "1905945                    yo @airberlin one ticket please   \n",
       "2313301  Hat bei @airberlin ja auch schon so gut geklap...   \n",
       "2482047  Moments which are gone since two years but sti...   \n",
       "2515956  Oh @airberlin, only 4 years ago. Feels like ye...   \n",
       "2712310  Danke für den Medienpreis Luft- und Raumfahrt ...   \n",
       "2903675  Die @airberlin Schoki performt immer noch. Ich...   \n",
       "3024084  I thought @airberlin’s customer service sucked...   \n",
       "3920865  WTF? 😱 Hmmm... Da ist schon nen Unterschied. 😂...   \n",
       "4247333  Was this steam-powered @Airbus #A319 the downf...   \n",
       "5631002  Interesting liveries! Somehow @airberlin is st...   \n",
       "5682425  Positioning into @manairport from @Gatwick_Air...   \n",
       "\n",
       "                                              conversation  \\\n",
       "10845    [Gute Nachrichten!! @airberlin fliegt wieder, ...   \n",
       "500375         [Heute back to the future mit @airberlin! ]   \n",
       "682085   [People of twitter, Ive just received a refund...   \n",
       "840200     [Now at #TXL still flying @airberlin #ber4evr ]   \n",
       "841780   [Post inspired by @biobooster. Perhaps the las...   \n",
       "1905945                  [yo @airberlin one ticket please]   \n",
       "2313301  [Hat bei @airberlin ja auch schon so gut gekla...   \n",
       "2482047  [Moments which are gone since two years but st...   \n",
       "2515956  [Oh @airberlin, only 4 years ago. Feels like y...   \n",
       "2712310  [Danke für den Medienpreis Luft- und Raumfahrt...   \n",
       "2903675  [Die @airberlin Schoki performt immer noch. Ic...   \n",
       "3024084  [I thought @airberlin’s customer service sucke...   \n",
       "3920865  [WTF? 😱 Hmmm... Da ist schon nen Unterschied. ...   \n",
       "4247333  [Was this steam-powered @Airbus #A319 the down...   \n",
       "5631002  [Interesting liveries! Somehow @airberlin is s...   \n",
       "5682425  [Positioning into @manairport from @Gatwick_Ai...   \n",
       "\n",
       "                  con_id_str_list con_id_str_list1 con_id_str_list2  \\\n",
       "10845     [1.131460172835152e+18]               []               []   \n",
       "500375   [1.1409059916403548e+18]               []               []   \n",
       "682085     [1.14386615313306e+18]               []               []   \n",
       "840200   [1.1466629144111064e+18]               []               []   \n",
       "841780   [1.1466999493059953e+18]               []               []   \n",
       "1905945   [1.167443139063419e+18]               []               []   \n",
       "2313301  [1.1765843832953815e+18]               []               []   \n",
       "2482047   [1.188949239147225e+18]               []               []   \n",
       "2515956  [1.1900190893113836e+18]               []               []   \n",
       "2712310  [1.1947833891083756e+18]               []               []   \n",
       "2903675  [1.1983769635739853e+18]               []               []   \n",
       "3024084  [1.2019450233628713e+18]               []               []   \n",
       "3920865  [1.2259016251282268e+18]               []               []   \n",
       "4247333  [1.2311682480471204e+18]               []               []   \n",
       "5631002  [1.2178902749842432e+18]               []               []   \n",
       "5682425  [1.2309627492676403e+18]               []               []   \n",
       "\n",
       "        con_id_str_list3     full_conversation_ids  \n",
       "10845                 []   [1.131460172835152e+18]  \n",
       "500375                []  [1.1409059916403548e+18]  \n",
       "682085                []    [1.14386615313306e+18]  \n",
       "840200                []  [1.1466629144111064e+18]  \n",
       "841780                []  [1.1466999493059953e+18]  \n",
       "1905945               []   [1.167443139063419e+18]  \n",
       "2313301               []  [1.1765843832953815e+18]  \n",
       "2482047               []   [1.188949239147225e+18]  \n",
       "2515956               []  [1.1900190893113836e+18]  \n",
       "2712310               []  [1.1947833891083756e+18]  \n",
       "2903675               []  [1.1983769635739853e+18]  \n",
       "3024084               []  [1.2019450233628713e+18]  \n",
       "3920865               []  [1.2259016251282268e+18]  \n",
       "4247333               []  [1.2311682480471204e+18]  \n",
       "5631002               []  [1.2178902749842432e+18]  \n",
       "5682425               []  [1.2309627492676403e+18]  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation('26223583')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6aef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
